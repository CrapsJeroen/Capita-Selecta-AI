\section{Task 2: Shikaku}\label{sec:shikaku}
\subsection{Introduction}

A shikaku is a puzzle consisting of a recangular grid where some positions on the grid are filled by a number. The goal of the puzzle is to paritition the grid into rectangles where each rectangle contains exactly one number and its area is equal to the value of that number. This a a fairly easy task to do manually, but it quickly gets more complicated as the puzzle gets larger. We have attempted to find a source which calculated the computational complexity of Shikaku puzzles. Sadly, we could only find references to a single article \cite{Takenaga}. This article claims that Shikaku puzzles are NP-Complete, but since we could not find a way to get a hold of the actual article itself we cannot verify its validity. \\





\begin{figure}[h]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  {\setstretch{0.875}
\begin{alltt}
\begin{center}
\textSFi\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFiii
\textSFxi 3   .   .   .   .   .   4 \textSFxi
\textSFxi                           \textSFxi
\textSFxi .   .   .   5   .   .   2 \textSFxi
\textSFxi                           \textSFxi
\textSFxi 2   2   .   .   3   .   . \textSFxi
\textSFxi                           \textSFxi
\textSFxi .   .   6   .   .   .   . \textSFxi
\textSFxi                           \textSFxi
\textSFxi .   .   .   5   .   .   3 \textSFxi
\textSFxi                           \textSFxi
\textSFxi .   .   3   2   .   2   . \textSFxi
\textSFxi                           \textSFxi
\textSFxi .   .   .   .   7   .   . \textSFxi
\textSFii\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFiv
\end{center}
\end{alltt}
}
  \caption{The Shikaku puzzle...}
  \label{fig:shikaku1a}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  {\setstretch{0.875}
\begin{alltt}
\begin{center}
\textSFi\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFvi\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFiii
\textSFxi 3   .   . \textSFxi .   .   .   4 \textSFxi
\textSFviii\textSFx\textSFx\textSFx\textSFvi\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFvii\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFvi\textSFx\textSFx\textSFx\textSFix
\textSFxi . \textSFxi .   .   5   .   . \textSFxi 2 \textSFxi
\textSFxi   \textSFviii\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFvi\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFix   \textSFxi
\textSFxi 2 \textSFxi 2   . \textSFxi .   3   . \textSFxi . \textSFxi
\textSFviii\textSFx\textSFx\textSFx\textSFvii\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFvii\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFv\textSFx\textSFx\textSFx\textSFix
\textSFxi .   .   6   .   .   . \textSFxi . \textSFxi
\textSFviii\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFvi\textSFx\textSFx\textSFx\textSFix   \textSFxi
\textSFxi .   .   .   5   . \textSFxi . \textSFxi 3 \textSFxi
\textSFviii\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFvi\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFix   \textSFxi   \textSFxi
\textSFxi .   .   3 \textSFxi 2   . \textSFxi 2 \textSFxi . \textSFxi
\textSFviii\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFvii\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFvii\textSFx\textSFx\textSFx\textSFvii\textSFx\textSFx\textSFx\textSFix
\textSFxi .   .   .   .   7   .   . \textSFxi
\textSFii\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFx\textSFiv
\end{center}
\end{alltt}
}
  \caption{... and its solution}
  \label{fig:shikaku1b}
\end{subfigure}
\caption{An example of a 7 by 7 Shikaku puzzle}
\label{fig:shikaku1}
\end{figure}

\subsection{Terminology}
Because a Shikaku cannot easily be described as a matrix of values, we will introduce some terminology. To denote the value of number on the grid write $\upsilon(x,y)$, where $x$ denotes the column of the grid and $y$ denotes the row. Note that both coordinates start at $1$. For instance: $\upsilon(1,1) = 3$ and $\upsilon(4,2) = 5$ in the Shikaku shown in figure~\ref{fig:shikaku1}.\\

The field itself has certain dimensions. All dimensions are denoted as a pair $s(w,h)$, where $w$ is the width (the amount of columns) and $h$ is the height (the amount of rows). In the running example, the dimensions of the field are $s(7,7)$. \\

To uniquely define a rectangle we need both a position on the grid (the top left corner) and a size. Positions are denoted in a similar way as sizes: $c(x,y)$ represents the grid position shared by column $x$ and row $y$. With this, we can define a rectangle like this: $rect(c(i,j),c(x,y),s(w,h))$. Here is $c(i,j)$ the number contained within the rectangle, $c(x,y)$ the top-left position of the rectangle and $s(w,h)$ the dimensions of the rectangle. We have decided to also put the position of the value contained by the rectangle in its definition to make the notation more analogous to our implemented code. As an example: $rect(c(7,1),c(4,1),s(4,1))$ is the rectangle in the top right corner of the solved puzzle in Figure \ref{fig:shikaku1b}. \\

While the following concept seems obvious from the drawings of the game, we will still include their formal definitions for the sake of completeness. The first important concept is $contains(c(x,y), s(w,h),c(i,j))$. This implies that the grid position $c(i,j)$ lies inside the boundary of the rectangle $rect(p,c(x,y),s(w,h))$.
\begin{equation}
contains(c(x,y), s(w,h),c(i,j)) \iff i \in [x,x+w-1] \wedge j \in [y,y+h-1]
\end{equation}
Another important concept is when two rectangles overlap. Two rectangles overlap when they share at least 1 grid position. It is expressed as $overlap(c(x_a,y_a), s(w_a,h_a),c(x_b,y_b), s(w_b,h_b))$. For $rect(p_a, c(x_a,y_a), s(w_a,h_a))$ and $rect(p_b,c(x_b,y_b), s(w_b,h_b))$ this means:
\begin{equation}
\begin{split}
overlap(c(x_a,y_a), s(w_a,h_a),c(x_b,y_b), s(w_b,h_b)) \iff x_a \leq x_b + w_b -1 \wedge x_b \leq x_a + w_a - 1  \\
									   \wedge \: y_a \leq y_b + h_b -1 \wedge y_b \leq y_a + h_a - 1 
\end{split}
\end{equation}

\subsection{Shikaku in ECLiPSe}
\subsubsection{Problem representation}
For our \texttt{ECLiPSe} Shikaku representation we make heavy use of libraries provided by the platform. We use the rect structure provided by the \texttt{gfd library} to represent the rectangles. This rectangle structure has fields for an $x$ and $y$ coordinate, as well as a $width$ and a $height$. The grid itself is not explicitely represented, it only comes forward in the constraints placed on the positions and sizes of the rectangles.

\subsubsection{Solver outline}
As a first step, the solver generates all of the variables needed to define the rectangles. \textsl{create\_rectangles} reads all the input values one by one and accumulates the constructed rectangles. \textsl{rectangle} actually takes the dimensions of the grid as well as the coordinates and value of the number on the grid and builds the variables of the rectangle with their constraints. The constraints make sure that the rectangle is the right size, fits on the grid and contains the given value. Note that this rectangle representation is not the structure from the \texttt{gfd library.}
\begin{lstlisting}
create_rectangles(_,_,[],_).
create_rectangles(Width,Height,[(X,Y,Val)|Tail],[R|Rects]) :-
        rectangle((X,Y,Val),Tail,Width,Height,R),
        create_rectangles(Width,Height,Tail,Rects).

rectangle((I,J,N),Others,Width,Height,rect(c(I,J),c(X,Y),s(W,H))):-
        X :: 1..Width,
        Y :: 1..Height,
        W :: 1..N,
        H :: 1..N,
        W*H #= N,
        X+W-1 #=< Width,
        Y+H-1 #=< Height,
        inside(c(X,Y),s(W,H),c(I,J)).
\end{lstlisting}

Once the list of rectangles in our notation has been generated, they are converted to the rect structure so we can use the \textsl{disjoint2} contstraint provided by the \texttt{gfd library}. The defining variables of all of the rectangles are then combined in a single flat list which is used to search for the solution.

\begin{lstlisting}
rect_to_struct(Rects,Structs),
disjoint2(Structs),
(foreach(rect(X,Y,W,H,_),Structs), foreach([X,Y,W,H],List) do
  	true
),
  flatten(List,FlatList)
\end{lstlisting}

All of these constraints are active constraints by the very nature of the \texttt{gfd library}. Whenever a new constraint is applied, it immediately impacts the domains of the variables this constraint impacts.
\subsubsection{Search strategies}
We have also experimented with search strategies for the Shikaku puzzle. Just like with the Sudoku puzzle, we have measured the time and amount of backtracks needed to solve each puzzle with several different search strategies. These strategies include \texttt{input order}, \texttt{first fail} and \texttt{anti first fail}. We have also implemented a search strategy we came up with to the speed up our CHR Shikaku solver. This strategy will select the largest rectangles first. A full explanation of the reasoning behind this search strategy can be found in Section~\ref{sec:CHR_opti} as the second additional optimization.

\begin{center}
\footnotesize
\begin{tabu}{|c|[2pt] c|c|c|c|c|c|c|c|}
\cline{2-9}
\multicolumn{1}{c|}{} & 
\multicolumn{2}{|c|}{\begin{sideways}\parbox{2cm}{ECLiPSe \\ Input Order}\end{sideways}} & 
\multicolumn{2}{|c|}{\begin{sideways}\parbox{2cm}{ECLiPSe \\ First Fail} \end{sideways}} & 
\multicolumn{2}{|c|}{\begin{sideways}\parbox{2cm}{ECLiPSe \\ Anti First Fail}\end{sideways}} & 
\multicolumn{2}{|c|}{\begin{sideways}\parbox{2cm}{ECLiPSe \\ Largest First}\end{sideways}}\\ \cline{2-9}
\multicolumn{1}{c|}{} 
		&    Time (s)	 &	 nbOfBt	&   Time (s) 	& 	nbOfBt	&   Time (s)	&     nbOfBt	&   Time (s) 	& nbOfBt 	\\ \tabucline[2pt]{-}             
tiny		&	0.00	&	0		&	0.00	&	0		&	0.00	&	0	&	0.01	& 	0	\\
helmut	&	0.01	&	639		&	0.00	&	829		&	0.00	&	262	&	0.00	& 	202	\\
p(0,1)		&	0.00	&	5		&	0.01	&	8		&	0.01	&	46	&	0.00	&	17	\\
p(0,2)		&	0.00	&	3		&	0.00	&	2		&	0.00	&	3	&	0.01	& 	3	\\
p(0,3)		&	0.00	&	8		&	0.00	&	6		&	0.00	&	4	&	0.00	& 	4	\\
p(0,4)		&	0.01	&	9		&	0.01	&	6		&	0.00	&	24	&	0.00	& 	18	\\
p(0,5)		&	0.00	&	4		&	0.00	&	5		&	0.00	&	48	&	0.00	& 	6	\\
p(1,1)		&	0.00	&	96		&	0.02	&	2910		&	0.00	&	71	&	0.00	&	133	\\
p(1,2)		&	0.01	&	244		&	0.01	&	320		&	0.00	&	112	&	0.00	& 	94	\\
p(1,3)		&	0.00	&	273		&	0.03	&	5233		&	0.00	&	49	&	0.01	& 	19	\\
p(1,4)		&	0.00	&	23		&	0.01	&	308		&	0.01	&	70	&	0.00	& 	57	\\
p(1,5)		&	0.01	&	244		&	0.01	&	2721		&	0.00	&	406	&	0.01	& 	760	\\
p(2,1)		&	0.41	&	64 058	&	0.49	&	70 838	&	0.00	&	155	&	0.00	&	558	\\
p(2,2)		&	0.04	&	4086		&	0.20	&	29 005	&	0.00	&	2368	&	0.03	& 	1827	\\
p(2,3)		&	0.01	&	257		&	1.77	&	241 490	&	0.03	&	306	&	0.00	& 	58	\\
p(2,4)		&	0.02	&	2251		&	3.34	&	628 514	&	0.01	&	168	&	0.00	& 	82	\\
p(2,5)		&	0.01	&	286		&	0.02	&	643		&	0.00	&	43	&	0.00	& 	124	\\
p(3,1)		&	0.16	&	14 322	&	TO	&	TO		&	0.04	&	1944	&	0.01	&	625	\\
p(3,2)		&	0.01	&	94		&	TO	&	TO		&	0.01	&	73	&	0.00	& 	158	\\
p(3,3)		&     	TO	&	TO		&	TO	&	TO		&	0.07	&	5526	&	0.14	& 	9944	\\ %  371.80	&	31 924 514    IO
p(3,4)		&	0.34	&	42452		&	TO	&	TO		&	0.03	&	2910	&	0.15	& 	14675	\\
p(3,5)		&	0.15	&	15445		&	TO	&	TO		&	0.02	&	820	&	0.00	& 	241	\\
p(4,1)		&	TO	&	TO		&	TO	&	TO		&	5.58	&   282 333	&	1.22	&	54745	\\
p(4,2)		&	0.91	&	91482		&	TO	&	TO		&	0.16	&    11 686	&	3.97	&   253 208	\\
p(4,3)		&	TO	&	TO		&	TO	&	TO		&	0.01	&	773	&	0.49	&     55 545	\\
p(4,4)		&	TO	&	TO		&	TO	&	TO		&	0.11	&	7098	&	0.37	&     30 352	\\
p(4,5)		&	TO	&	TO		&	TO	&	TO		&	0.21	&     18 537	&	0.88	&     62 447	\\
p(5,1)		&	TO	&	TO		&	TO	&	TO		&	7.90	&     307 116	&      217.67	&  8 457 170	\\
p(5,2)		&	TO	&	TO		&	TO	&	TO		&	TO	&	TO	&	TO	& 	TO	\\
p(5,3)		&	TO	&	TO		&	TO	&	TO		&	TO	&	TO	&	TO	& 	TO	\\
p(5,4)		&	TO	&	TO		&	TO	&	TO		&	TO	&	TO	&	TO	& 	TO	\\
p(5,5)		&	TO	&	TO		&	TO	&	TO		&	TO	&	TO	&	TO	& 	TO	\\
p(6,1)		&	TO	&	TO		&	TO	&	TO		&	TO	&	TO	&	TO	&	TO	\\

\hline
\end{tabu}
\captionof{table}{The execution time and number of backtracks for all the puzzles with different search methods.}
\end{center}


The first observation from these results is that \texttt{first fail} is by far the worst search strategy and \texttt{anti first fail} is the best search strategy. Our own largest first strategy ends up being slightly slower than \texttt{anti first fail}. This is a very strange result. First fail selects the variables with the smallest domain first to minimize the amount of backtracks but in this case it has the exact opposite effect. \\

We believe that the fact that largest first and anti first fail are so closely matched is an important clue as to why this happens. Variables belonging to larger rectangles have a larger domain than those belonging to small rectangles. The width and height can each generally be any of the divisors of the area of the rectangle. Larger numbers have generally more divisors so the domains of these variables are generally larger. The possible coordinates for the top left corner are directly coupled to the size of the rectangle. A larger rectangle can be positioned in more ways around the value than a smaller rectangle, making the domain for the coordinates of the top left corner larger.\\

This explains why largest first and anti first fail behave similarly, but not why they perform better. It is here that the insight given by figuring out why our CHR implementation was initially performing poorly helped us put these results into context. Our suspicion is that selecting larger rectangles limits the domains of other rectangles much more strongly because they are generally surrounded by more neighboring rectangles. Even though the large rectangles have a much larger domain themselves, the benefits of greatly reducing the domains of many other rectangles outweighs the downside of deeper backtracks as a result of selecting the larger domains first.

\subsubsection{Adding a redundant constraint}
We have also added a redundant constraint to our solver. This constraint explicitly prohibits rectangles from containing other values than the one for which they are defined. This can rule out many position/size combinations before the search begins, preventing unnecessary backtracks. Our implementation of this constraint was inspired by the experiments of H. Simonis \cite{Simonis}
\begin{center}
\footnotesize
\begin{tabu}{|c|[2pt] c|c|c|c|c|c|c|c|}
\cline{2-9}
\multicolumn{1}{c|}{} & 
\multicolumn{2}{|c|}{\begin{sideways}\parbox{2cm}{ECLiPSe \\ Input Order}\end{sideways}} & 
\multicolumn{2}{|c|}{\begin{sideways}\parbox{2cm}{ECLiPSe \\ First Fail} \end{sideways}} & 
\multicolumn{2}{|c|}{\begin{sideways}\parbox{2cm}{ECLiPSe \\ Anti First Fail}\end{sideways}} & 
\multicolumn{2}{|c|}{\begin{sideways}\parbox{2cm}{ECLiPSe \\ Largest First}\end{sideways}}\\ \cline{2-9}
\multicolumn{1}{c|}{} 
		&    Time (s)	 &	 nbOfBt	&   Time (s) 	& 	nbOfBt	&   Time (s)	&     nbOfBt	&   Time (s) 	& nbOfBt 	\\ \tabucline[2pt]{-}             
tiny		&	0.00	&	0		&	0.00	&	0		&	0.00	&	0	&	0.01	& 	0	\\
helmut	&	0.01	&	364		&	0.00	&	281		&	0.00	&	28	&	0.00	& 	171	\\
p(0,1)		&	0.01	&	5		&	0.01	&	8		&	0.01	&	39	&	0.01	&	15	\\
p(0,2)		&	0.01	&	3		&	0.00	&	2		&	0.00	&	3	&	0.00	& 	3	\\
p(0,3)		&	0.01	&	5		&	0.00	&	5		&	0.00	&	9	&	0.00	& 	4	\\
p(0,4)		&	0.00	&	5		&	0.00	&	6		&	0.00	&	15	&	0.00	& 	14	\\
p(0,5)		&	0.00	&	4		&	0.01	&	5		&	0.00	&	42	&	0.00	& 	6	\\
p(1,1)		&	0.01	&	44		&	0.01	&	1245		&	0.00	&	59	&	0.00	&	98	\\
p(1,2)		&	0.01	&	53		&	0.01	&	110		&	0.00	&	65	&	0.00	& 	44	\\
p(1,3)		&	0.00	&	188		&	0.03	&	2308		&	0.00	&	40	&	0.01	& 	18	\\
p(1,4)		&	0.00	&	12		&	0.01	&	104		&	0.01	&	57	&	0.00	& 	41	\\
p(1,5)		&	0.01	&	62		&	0.02	&	1237		&	0.00	&	279	&	0.01	& 	383	\\
p(2,1)		&	0.09	&	6664		&	0.35	&	31 785	&	0.01	&	49	&	0.01	&	241	\\
p(2,2)		&	0.02	&	1110		&	0.22	&	17 867	&	0.05	&	2051	&	0.03	& 	1725	\\
p(2,3)		&	0.02	&	156		&	1.39	&	100 663	&	0.01	&	119	&	0.01	& 	32	\\
p(2,4)		&	0.02	&	1056		&	7.01	&	570 537	&	0.01	&	128	&	0.00	& 	57	\\
p(2,5)		&	0.02	&	258		&	0.03	&	643		&	0.01	&	35	&	0.01	& 	118	\\
p(3,1)		&	0.04	&	1708		&	TO	&	TO		&	0.04	&	659	&	0.02	&	331	\\
p(3,2)		&	0.01	&	51		&	TO	&	TO		&	0.01	&	64	&	0.01	& 	92	\\
p(3,3)		&     	TO	&	TO		&	TO	&	TO		&	0.03	&	579	&	0.12	& 	3753	\\ % 430.24	&	17 847 417    IO
p(3,4)		&	0.19	&	7143		&	TO	&	TO		&	0.04	&	1698	&	0.15	& 	6343	\\
p(3,5)		&	0.02	&	702		&	TO	&	TO		&	0.02	&	339	&	0.01	& 	224	\\
p(4,1)		&	TO	&	TO		&	TO	&	TO		&	7.34	&   118 200	&	1.06	&    20 003	\\
p(4,2)		&	TO	&	TO		&	TO	&	TO		&	0.36	&    7418	&	3.32	&   91 431	\\
p(4,3)		&	TO	&	TO		&	TO	&	TO		&	0.01	&	317	&	0.16	&     6991	\\
p(4,4)		&	TO	&	TO		&	TO	&	TO		&	0.18	&	4893	&	0.54	&     20 606	\\
p(4,5)		&	TO	&	TO		&	TO	&	TO		&	0.09	&     1988	&	0.28	&     7936	\\
p(5,1)		&	TO	&	TO		&	TO	&	TO		&	0.96	&     15 655	&        54.4	&     957 812	\\
p(5,2)		&	TO	&	TO		&	TO	&	TO		&	42.19	&     585 179	&        141.1	& 1 824 228	\\
p(5,3)		&	TO	&	TO		&	TO	&	TO		&	TO	&	TO	&	4.44	& 116 811	\\
p(5,4)		&	TO	&	TO		&	TO	&	TO		&	TO	&	TO	&	44.46	&   978 549	\\
p(5,5)		&	TO	&	TO		&	TO	&	TO		&	TO	&	TO	&	TO	& 	TO	\\
p(6,1)		&	TO	&	TO		&	TO	&	TO		&	TO	&	TO	&	TO	&	TO	\\

\hline
\end{tabu}
\captionof{table}{The execution time and number of backtracks for all the puzzles with different search methods when the additional constraint is applied.}
\end{center}

We see an almost unilateral improvement for the amount of backtracks among all search strategies, as expected. What we did not expect is that our largest first search method managed to solve  two puzzles that the anti first fail was not able to solve. Although anti first fail is stil faster for most other puzzles. We believe that due to the extra constraint, the assumption that variables belonging to a larger rectangle usually have a larger domain no longer holds. It is hard to draw conclusions from this limited set of data. \\
However, we suspect that because this assumption is likely no longer true, the benefit of reducing the domains of other rectangles may no longer outweigh increased amount of backtracks when solving large puzzles. More domain-reducing optimizations would be needed to fully investigate this hypothesis. 

\subsection{Shikaku in CHR}
\subsubsection{Problem representation}
The CHR implementation of our Shikaku solver makes less use of libraries than our ECLiPSe implementation. The first step is generating what we call temporary rectangles. These are rectangles which have not yet been defined fully defined. The goal of the solver is to fully define all these temporary rectangles while respecting the given constraints. This is the solution for the puzzle. The temporary rectangles consist of a grid locations corresponding to the location of the value it contains, and a list of tuples containing a grid location and dimensions each. Each tuple represents a possible top left corner of the rectangle and its size. 
\\ \\
Many of the constraints can be checked without having to know about other rectangles. This makes it possible to completely apply these constraints without any backtracking at all. We do this by checking against these constraints when generating the list of tuples for each temporary rectangle. The constraints taken into account when generating the domain of possible rectangles in the first place are: Each rectangle needs to have an area equal to the value it contains, each rectangle needs to actually contain the value it claims to contain in its definition, and each rectangle needs to fully fit within the field. Because these constraints are applied proactively, they are active constraints.

\subsubsection{Solver outline}
In the code below, \texttt{make\_domains} iteratively calls \texttt{generate\_options} for each of the values on the grid. With the resulting list of options, a \texttt{rect\_temp} CHR constraint is generated. \texttt{generate\_options} collects all the possible options generated by \texttt{generate\_single\_option} and returns them as a list. \texttt{generate\_single\_option} contains the constraints described above and will return all possible solutions satisfying those constraints one by one. 

\begin{lstlisting}
make_domains([],_) <=> true.
make_domains([(X,Y,Value)|Points],FieldSize) <=>
	generate_options(c(X,Y),Value,FieldSize,OptionsList),
	rect_temp(c(X,Y),OptionsList),
	make_domains(Points,FieldSize).
	
generate_options(Pos,Value,FieldSize,OptionsList):-
    findall(Option,
		generate_single_option(Pos,Value,FieldSize,Option),
		OptionsList)
		
generate_single_option(Point,Value,FieldSize,(Pos,Size)):-
	correct_size(Size,Value),
	contains(Pos,Size,Point),
	in_field(Pos,Size,FieldSize).
\end{lstlisting}

Once all these temporary rectangles are generated, only one more constraint needs to be checked: Rectangles may not overlap eachother.

\begin{lstlisting}
rect(_,Pos,Size) \ rect_temp(Point,OptionsList) <=>
	remove_rect_overlap(Pos,Size,OptionsList,NewList),
	OptionsList \== NewList
	| rect_temp(Point,NewList).
	
failure @ rect_temp(_,[]) <=> fail.
\end{lstlisting}

This constraint removes all overlapping options from the list of options of every temporary rectangle. If at some point there is a temporary rectangle with no options left, the search will backtrack. This constraint is also an active constraint because it proactively limits the domains of all other temporary rectangles as soon as a permanent rectangle is added.

\begin{lstlisting}
search, rect_temp(Point,OptionsList) <=>
	try_option(Point,OptionsList),
	search.
search <=> true.

try_option(_,[]) :- fail.
try_option(Point,[(Pos,Size)|Options]):-
    rect(Point,Pos,Size)
    ;
    try_option(Point,Options).
\end{lstlisting}

The search is very simple. It picks a temporary rectangle and tries every option in its list of options. This is done by constructing a permanent rectangle from the option and checking whether or not that leads to a failure. If a failure is found, backtracking happens and the next option is tried. In case that not a single option succeeds, another failure is caused which will backtrack the search to its last decision. Once a permanent rectangle is found that does not lead to a failure, the search starts over again with the next temporary rectangle.

\newpage
\subsubsection{Additional optimizations}
\paragraph{First optimization}
\label{sec:CHR_opti}
Just like with out ECLiPSe implementation, one additional constraint is that a rectangle may not contain any values other than the one for which it is combined. This constraint is already provided by the combination of having each rectangle contain the value in its definition and not allowing rectangles to overlap. The critical part here is that the solver can decide whether ot not a rectangle contains other values without the need to know about other rectangles. This observation allows the solver to limit the domains of each temporary rectangle even more before and prevents a large amount of backtracks. The way we implemented this is very similar to how the overlap between rectangles is handled. Since this is constraint proactively limits the search domain, it is also an active constraint.

\begin{lstlisting}
rect_temp(RefPoint,_) \ rect_temp(Point,OptionsList) <=>
	remove_point_overlap(RefPoint,OptionsList,NewList),
	OptionsList \== NewList
	| rect_temp(Point,NewList).
\end{lstlisting}

\begin{center}
\footnotesize
\begin{tabu}{|c|[2pt] c|c|c|c|}
\cline{2-5}
\multicolumn{1}{c|}{} & 
\multicolumn{2}{|c|}{\begin{sideways}\parbox{2cm}{CHR \\ Basic solver}\end{sideways}} & 
\multicolumn{2}{|c|}{\begin{sideways}\parbox{2cm}{CHR \\ Additional Constraint} \end{sideways}} \\ \cline{2-5}
\multicolumn{1}{c|}{} 
		&    Time (s)	 &	 inferences		&   Time (s) 	& 	inferences		\\ \tabucline[2pt]{-}             
tiny		&	0.00	&	3084			&	0.00	&	4431	 		\\
helmut	&	0.07	&	517 641		&	0.04	&	182 333		\\
p(0,1)		&	0.01	&	28 257		&	0.01	&	29 899		\\
p(0,2)		&	0.01	&	33 808		&	0.01	&	31 088		\\
p(0,3)		&	0.01	&	45 009		&	0.00	&	34 562		\\
p(0,4)		&	0.00	&	46 032		&	0.00	&	35 782		\\
p(0,5)		&	0.00	&	24 721		&	0.00	&	36 614		\\
p(1,1)		&	0.02	&	228 824		&	0.02	&	87 952		\\
p(1,2)		&	0.02	&	59 097		&	0.02	&	122 824		\\
p(1,3)		&	0.01	&	65 448		&	0.02	&	83 102		\\
p(1,4)		&	0.02	&	74 441		&	0.02	&	61 179		\\
p(1,5)		&	0.02	&	190 380		&	0.01	&	62 018		\\
p(2,1)		&	0.71	&	6 507 516		&	0.05	&	357 974		\\
p(2,2)		&	2.75	&	25 407 954		&	0.10	&	758 057		\\
p(2,3)		&	0.37	&	3 295 683		&	0.03	&	214 269		\\
p(2,4)		&	0.62	&	5 881 840		&	0.05	&	346 635		\\
p(2,5)		&	0.94	&	8 888 968		&	0.04	&	224 674		\\
p(3,1)		&	TO	&	TO			&	0.38	&	3 458 752		\\
p(3,2)		&	0.25	&	2 234 784		&	0.12	&	1 067 363		\\
p(3,3)		&     	TO	&	TO 			&	0.25	&	2 140 242		\\
p(3,4)		&	19.56	&	185 782 112		&	0.08	&	650 691		\\
p(3,5)		&	TO	&	TO			&	0.59	&	5 452 485		\\
p(4,1)		&	TO	&	TO			&	TO	&	TO			\\
p(4,2)		&	TO	&	TO			&	TO	&	TO			\\
p(4,3)		&	TO	&	TO			&	TO	&	TO			\\
p(4,4)		&	TO	&	TO			&	4.99	&	46 192 343		\\
p(4,5)		&	TO	&	TO			&	1.29	&	11 824 321		\\
p(5,1)		&	TO	&	TO			&	TO	&	TO			\\
p(5,2)		&	TO	&	TO			&	33.47	&	310 379 885		\\
p(5,3)		&	TO	&	TO			&	TO	&	TO			\\
p(5,4)		&	TO	&	TO			&	1.70	&	14 858 545		\\
p(5,5)		&	TO	&	TO			&	TO	&	TO			\\
p(6,1)		&	TO	&	TO			&	TO	&	TO			\\

\hline
\end{tabu}
\captionof{table}{The execution time and number of inferences of the basic solver and the solver with an additional constraint}
\end{center}

Just like in our other implementation, the additional redundant constraint as a positive effect on performance. Where the basic solver struggles to solve the 15 by 15 puzzles, the improved solver solves all of the 15 by 15 puzzles and even managed to solve some of the 20 by 20 and 25 by 25 puzzles. The constraint clearly has significantly reduced the search space.
\paragraph{Second optimization}
Our second optimization is not a constraint, but instead it is a smarter search heuristic. Our first approach to searching did not define an order in which the temporary rectangles should be searched. During testing we observed that a small rectangle (for instance size 2) placed the wrong way early into the search process could make the solver take a really long time trying to fit all the other rectangles. The solver would often fail really deep into the search and have to backtrack all the way to the start. \\
 Another observation was the fact that the really large rectangles in the larger puzzles only had relatively few options compared to their size thanks to our previous optimization. Most options would get filtered out right away because they would contain other values. These large rectangles also had a very large effect on the domains of other temporary rectangles. A rectangle of size 2 can only affect at least one temporary rectangle, but a rectangle of size 30 or higher will have many neighbors. Our reasoning was that by trying to place the large rectangles first, the solver could significantly reduce the search domain going forward and limit the depth at which backtracking usually occurs.
 \begin{lstlisting}
 search(N), rect_temp(Point,OptionsList) <=>
	member((_,s(Width,Height)),OptionsList),
	Width*Height >= N
	| try_option(Point,OptionsList),
	search(N).
search(0) <=> true.
search(N) <=> N1 is N - 1, search(N1).
\end{lstlisting}
The search constraint should be initialized with a value at least as large as the largest possible rectangle. For simiplicity we simply initialize it with the total area of the grid, but looking for the highest value on the grid will also work. In each search step, it will try to place rectangles of at least the current value. If no temporary rectangles of sufficient size are matched, the value for the search is decremented repeatedly until the next match. \\

We can immediately see in Table \ref{table:last} that for the first time one of our Shikaku solvers manages to solve the largest puzzle. At 30 by 40 this puzzle is now just barely solvable using the new search heuristic. Knowing this, it is no surprise that we can see significant improvements across the board when compared to the basic solver. We believe that selecting the large rectangles first significantly reduces the search domain of many other rectangles, just like in our ECLiPSe implementation. \\
When combining those two optimizations, the solver becomes even faster. We expected some gains in performance but we were surprised by just how much faster it became. Even the hardest puzzles in the data set take no longer than a few second to solve. We also do not see any of the large peaks in the number of inferences required to solve certain puzzles. All puzzles of the same size now take roughly the same amount of inferences to solve.

\begin{center}
\footnotesize
\begin{tabu}{|c|[2pt] c|c|c|c|c|c|}
\cline{2-7}
\multicolumn{1}{c|}{} & 
\multicolumn{2}{|c|}{\begin{sideways}\parbox{2cm}{CHR \\ Basic Solver}\end{sideways}} & 
\multicolumn{2}{|c|}{\begin{sideways}\parbox{2cm}{CHR \\ Largest First} \end{sideways}} & 
\multicolumn{2}{|c|}{\begin{sideways}\parbox{2cm}{CHR \\ Combined}\end{sideways}} \\ \cline{2-7} 
\multicolumn{1}{c|}{} 
		&    Time (s)	 &	 inferences		&   Time (s) 	& 	inferences	&   Time (s)	&     inferences	 	\\ \tabucline[2pt]{-}             
tiny		&	0.00	&	3084			&	0.00	&	3328	 			&	0.00	&	3660		\\
helmut	&	0.07	&	517 641		&	0.02	&	133 198			&	0.03	&	159 904		\\
p(0,1)		&	0.01	&	28 257		&	0.01	&	29 134			&	0.01	&	25 657		\\
p(0,2)		&	0.01	&	33 808		&	0.01	&	40 705			&	0.01	&	26 494		\\
p(0,3)		&	0.01	&	45 009		&	0.01	&	34 550			&	0.01	&	30 800		\\
p(0,4)		&	0.00	&	46 032		&	0.01	&	29 512			&	0.01	&	31 178		\\
p(0,5)		&	0.00	&	24 721		&	0.01	&	36 639			&	0.00	&	32 022		\\
p(1,1)		&	0.02	&	228 824		&	0.02	&	18 331			&	0.02	&	76 854		\\
p(1,2)		&	0.02	&	59 097		&	0.02	&	119 194			&	0.02	&	112 199		\\
p(1,3)		&	0.01	&	65 448		&	0.02	&	108 673			&	0.01	&	69 607		\\
p(1,4)		&	0.02	&	74 441		&	0.02	&	76 805			&	0.01	&	67 014		\\
p(1,5)		&	0.02	&	190 380		&	0.01	&	73 670			&	0.01	&	63 522		\\
p(2,1)		&	0.71	&	6 507 516		&	0.15	&	1 392 238			&	0.08	&	612 939		\\
p(2,2)		&	2.75	&	25 407 954		&	0.08	&	699 178			&	0.04	&	262 105		\\
p(2,3)		&	0.37	&	3 295 683		&	0.04	&	234 719			&	0.02	&	200 600		\\
p(2,4)		&	0.62	&	5 881 840		&	0.04	&	300 085			&	0.04	&	233 985		\\
p(2,5)		&	0.94	&	8 888 968		&	0.04	&	263 053			&	0.03	&	225 389		\\
p(3,1)		&	TO	&	TO			&	0.28	&	2 504 518			&	0.09	&	677 965		\\
p(3,2)		&	0.25	&	2 234 784		&	0.08	&	565 555			&	0.06	&	519 563		\\
p(3,3)		&     	TO	&	TO 			&	0.13	&	1 085 122			&	0.11	&	893 334		\\
p(3,4)		&	19.56	&	185 782 112		&	0.28	&	2 519 750			&	0.08	&	653 212		\\
p(3,5)		&	TO	&	TO			&	0.24	&	2 306 833			&	0.10	&	735 528		\\
p(4,1)		&	TO	&	TO			&	0.78	&	7 359 453			&	0.35	&  	3 055 868		\\
p(4,2)		&	TO	&	TO			&	0.29	&	2 587 162			&	0.21	&    	1 784 959		\\
p(4,3)		&	TO	&	TO			&	0.34	&	2 972 902			&	0.15	&	1 351 991		\\
p(4,4)		&	TO	&	TO			&	1.03	&	10 035 411			&	0.28	&	2 593 443		\\
p(4,5)		&	TO	&	TO			&	0.34	&	3 143 284			&	0.20	&   	1 696 816		\\
p(5,1)		&	TO	&	TO			&	12.79	&	123 529 917			&	0.59	&     	5 084 746		\\
p(5,2)		&	TO	&	TO			&	95.54	&	898 562 921			&	1.09	&     	7 776 059		\\
p(5,3)		&	TO	&	TO			&	2.93	&	26 276 870			&	0.41	&	3 511 457		\\
p(5,4)		&	TO	&	TO			&	7.61	&	75 856 587			&	1.33	&	12 134 475		\\
p(5,5)		&	TO	&	TO			&	44.24	&	437 154 752			&	3.65	&	35 034 535		\\
p(6,1)		&	TO	&	TO			&      163.78	&	1 556 158 403		&	4.05	&	37 371 197		\\

\hline
\end{tabu}
\captionof{table}{The execution time and number of inferences of the basic solver, the solver with an improved search selection order and the final solver with both optimizations combined.}
\label{table:last}
\end{center}